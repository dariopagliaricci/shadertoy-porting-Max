<jittershader name="default">
	<description>Default Slab </description>

	<param name="MVP" type="mat4" state="MODELVIEW_PROJECTION_MATRIX" />

	<param name="pos" type="vec3" state="POSITION" />
	<param name="uv" type="vec2" state="TEXCOORD" />

	<param name="viewPort" type="vec2" state="VIEWPORT" />
	<param name="iTime" type="float" default="0.0" />
	<param name="iFrame" type="int" default="0" />
	<param name="iChannel0" type="int" default="0" />
	<param name="iChannel1" type="int" default="1" />
    <param name="iChannel3" type="int" default="2" />


	<language name="glsl" version="1.5">

		<bind param="MVP" program="vp" />

		<bind param="pos" program="vp" />
		<bind param="uv" program="vp" />

		<bind param="viewPort" program="fp" />
		<bind param="iTime" program="fp" />
		<bind param="iFrame" program="fp" />
		<bind param="iChannel0" program="fp" />
		<bind param="iChannel1" program="fp" />
		<bind param="iChannel3" program="fp" />

		<program name="vp" type="vertex"  >
		<![CDATA[
			#version 330 core
			
			in vec3 pos;
			in vec2 uv;

			out jit_PerVertex {
				vec2 uv;
			} jit_out;
			uniform mat4 MVP;

			
			void main(void) {
				gl_Position = MVP*vec4(pos, 1.);
				jit_out.uv = uv;

			}
		]]>
		</program>
		
		<program name="fp" type="fragment"  >
		<![CDATA[
#version 330 core

in jit_PerVertex {
	vec2 uv;

} jit_in;
layout (location = 0) out vec4 outColor;

uniform vec2 viewPort;
uniform float iTime;
uniform int iFrame;
uniform sampler2D iChannel0;
uniform sampler2D iChannel1;
uniform sampler2D iChannel3;

/*

    Multisample Cell Traversal
    --------------------------
    
    I've often wondered why some of us, incuding myself, like that noisy path 
    traced aesthetic whilst others don't. I'm not sure why, but for me, I 
    associate noisy light based stuff with elite democoders from the past.

    Either way, I'd imagine virtually all of us prefer crisp clean path 
    traced imagery over the noisy ones. Unfortunately, the former is nearly
    impossible to achieve in realtime inside a pixelshader environment for 
    anything but the simplest of scenes.
    
    This particular example represents a compromise. The results wouldn't pass 
    the static imagery test, or the intersting scene test. :D However, it's 
    pretty good for something produced under realtime constraints. By the way, 
    I have an asymmetric quad traversal rendered in the same style that I'll 
    post pretty soon.
    
    In order to achieve this, I've performed a cell by cell hexagon traversal 
    and rendered just six samples with three bounces each. That amount of work 
    is not ideal, but an average machine should be able to handle it. Six 
    samples produces a pretty noisy result, so I've applied IQ's temporal 
    reprojection code to give the impression that there are eight times that, 
    so 48 samples in all -- The trade-off is some slight temporal blurring. 
    However, even that isn't quite enough to clean up the noise, so I've 
    included a denoising pass in Buffer B.
    
    Overall, the image isn't perfect, but it's not too bad for just a few 
    samples. The reason someone would go through all that trouble is a mixture
    of academic curiosity and to produce lighting in a scene that is not
    possible to recreate using more common realtime Blinn-Phong related 
    lighting methods. 
    
    
    
    Other examples:
    
    
    // Beautiful, concise example.
    Small Pathtracer - fizzer
    https://www.shadertoy.com/view/ll3SDr
    
    // Path tracing a heap of boxes in realtime with the help of camera
    // reprojection -- It's one of IQ's many understated examples that 
    // does something amazing.
    Some boxes - iq
    https://www.shadertoy.com/view/Xd2fzR
    
    // One of my favorite realtime path tracing examples.
    20211031_Shader Royale (0b5vr) - 0b5vr
    https://www.shadertoy.com/view/7td3zn


*/


// The default hexagon grid. Commenting it out will give rectangles.
// #define HEXAGON

// Unfortunately, if you have a slow machine IQ's temporal reprojection option
// will usually result in blur. Regular accumulation might work, but you'll 
// probably have to use straight samples (BUFF_ACCUM 0).
// Buffer accumulation style:
// 0: No accumulation -- Noisy, sharper picture, but with no blur. 
// 1: Regular accumulation with no reprojection -- A mixture.
// 2: Temporal reprojection. -- Smoother for faster machines.
#define BUFF_ACCUM 1


// Far plane. I've kept it close.
#define FAR 25.


///////////////

// Standard 2D rotation formula.
mat2 rot2(in float a){ float c = cos(a), s = sin(a); return mat2(c, -s, s, c); }


// Random seed value.
vec2 seed = vec2(.1023, .2157);

/*
// Basic random function. Not a lot of thought was put into it. Using one of
// the more reliable positive integer based ones might be better... Common sense
// would dictate that integers work faster, but on a GPU, I'm not really sure.
vec2 hash22() {
    
    //seed += vec2(.723, .647);
    //return texture(iChannel2, seed*43266.1341).xy;
    
    seed = fract(seed + vec2(.723, .647));
    return fract(sin(vec2(dot(seed.xy, vec2(12.989, 78.233)), dot(seed.xy, vec2(41.898, 57.263))))
                    *vec2(43758.5453, 23421.6361));
}
*/
 
// A slight variation on a function from Nimitz's hash collection, here: 
// Quality hashes collection WebGL2 - https://www.shadertoy.com/view/Xt3cDn
vec2 hash22(){

    // I should probably use a "uvec2" seed, but I hacked this from an old
    // example. I'll update it later.
    seed = fract(seed + vec2(.7123, .6457));
    uvec2 p = floatBitsToUint(seed);
    
    // Modified from: iq's "Integer Hash - III" (https://www.shadertoy.com/view/4tXyWN)
    // Faster than "full" xxHash and good quality.
    p = 1103515245U*((p>>1U)^(p.yx));
    uint h32 = 1103515245U*((p.x)^(p.y>>3U));
    uint n = h32^(h32>>16);

    uvec2 rz = uvec2(n, n*48271U);
    // Standard uvec2 to vec2 conversion with wrapping and normalizing.
    return vec2((rz>>1)&uvec2(0x7fffffffU))/float(0x7fffffff);
}
 

/*
vec3 rnd23(){

    seed = fract(seed + vec2(.7423, .6047));
    uvec2 x = floatBitsToUint(seed);
    uint n = baseHash(x);
    uvec3 rz = uvec3(n, n*16807U, n*48271U);
    return vec3((rz >> 1) & uvec3(0x7fffffffU))/float(0x7fffffff);
}
*/

// IQ's vec2 to float hash.
float hash21(vec2 p){ return fract(sin(mod(dot(p, vec2(27.619, 57.583)), 6.2831))*43758.5453); }

// IQ's vec3 to float hash.
//float hash31(in vec3 p){ return fract(sin(dot(p, vec3(91.537, 151.761, 72.453)))*435758.5453); }


 
// A nice random hemispherical routine taken out of one of IQ's examples.
// The routine itself was written by Fizzer.
vec3 cosDir( in float seed, in vec3 n){

    vec2 rnd = hash22();
    float u = rnd.x;
    float v = rnd.y;
    
    // Method 1 and 2 first generate a frame of reference to use with an arbitrary
    // distribution, cosine in this case. Method 3 (invented by fizzer) specializes 
    // the whole math to the cosine distribution and simplfies the result to a more 
    // compact version that does not depend on a full frame of reference.

    // Method by fizzer: http://www.amietia.com/lambertnotangent.html
    float a = 6.2831853*v;
    u = 2.*u - 1.;
    return normalize(n + vec3(sqrt(1. - u*u)*vec2(cos(a), sin(a)), u));
    
}

////////////////

// The following is based on John Hable's Uncharted 2 tone mapping, which
// I feel does a really good job at toning down the high color frequencies
// whilst leaving the essence of the gamma corrected linear image intact.
//
// To arrive at this non-tweakable overly simplified formula, I've plugged
// in the most basic settings that work with scenes like this, then cut things
// right back. Anyway, if you want to read about the extended formula, here
// it is.
//
// http://filmicworlds.com/blog/filmic-tonemapping-with-piecewise-power-curves/
// A nice rounded article to read. 
// https://64.github.io/tonemapping/#uncharted-2
vec4 uTone(vec4 x){
    return ((x*(x*.6 + .1) + .004)/(x*(x*.6 + 1.)  + .06) - .0667)*1.933526;    
}



// Polygon scale: Smaller scales mean smaller grid shapes, thus more of
// them. Sometimes, people (including myself) will confuse matters and 
// use the inverse number. :)
#ifdef HEXAGON
#define sqrt3 1.7320508 // sqrt(3.).
// Hexagons will only work with the "1 to sqrt3" ratio -- Scaling is fine though. 
// At some stage, I'll arrange for anything to work, but it's not trivial.
const vec2 s = vec2(1, sqrt3)/2.; 
#else
// Rectangle dimensions. Any numbers should work. Obviously, vec2(1)
// will produce squares.
const vec2 s = vec2(2, 1)/3.; 
#endif

 // Ray origin, ray direction, point on the line, normal. 
float rayLine(vec2 ro, vec2 rd, vec2 p, vec2 n){
   
   // This it trimmed down, and can be trimmed down more. Note that 
   // "1./dot(rd, n)" can be precalculated outside the loop. However,
   // this isn't a GPU intensive example, so it doesn't matter here.
   return dot(p - ro, n)/dot(rd, n);

}
/*
// Grid cell function.
vec2 gridID(vec2 p){
    // Using the rectangle's center position for the ID. 
    return floor(p/s) + .5;

}
*/

// Sign function without the zero, which can cause problems for some routines.
vec3 sign2(in vec3 p){ return vec3(p.x<0.? -1 : 1, p.y<0.? -1 : 1,  p.z<0.? -1 : 1); }
//vec2 sign2(in vec2 p){ return vec2(p.x<0.? -1 : 1, p.y<0.? -1 : 1); }
 


// Grid cell function.
vec2 gridID(vec2 p){

    
    // Returns the cell center position-based IDs for a hexagon 
    // grid, offset rectangle grid and regular rectangle grid.

    #ifdef HEXAGON
    
    // Hexagons.  
    //
    vec4 hC = floor(vec4(p/s, p/s - vec2(.5, sqrt3/3.))) + .5;
    vec4 h = vec4(p - hC.xy*s, p - (hC.zw + .5)*s);
    return dot(h.xy, h.xy)<dot(h.zw, h.zw) ? hC.xy : hC.zw + .5;
    
    #else
    
    // Rectangles.   
    //    
 
    // Rectangles with no offset. 
    vec2 ip = floor(p/s) + .5;
    return ip;
     
    
    #endif
  
}

float h(vec2 p){

    //return hash21(p)*4.;
    
    // Only one texture read.
    // I'm using the Shadertoy noise texture, which I'm assuming is already in
    // linear form, so I'm not performing the rought sRGB to linear conversion... 
    // I don't know for sure, but it doesn't matter here.
    vec3 tx = texture(iChannel0, p/64.).xyz;  
    //tx *= tx; // Rough sRGB to linear conversion.
    // Greyscale height. Using "tx.x" would be OK, too.
    float f = dot(tx, vec3(.299, .587, .114));
    //float f2 = f;
 
    return f*6.;
    //return floor(f*48.)/8.;//floor((f*8. + f2*4.)*8.)/8.;
    
    //return (sin(f*6.2831*4. + iTime)*.5 + .5)*1.;

}
 
// A standard square cell by cell traversal. Not optimized enough for path tracing
// purposes, but it's reasonable quick otherwise.
vec4 raycast(vec3 ro, vec3 rd){
   
    // Initial result.
    vec4 res = vec4(FAR, 0, 0, 0);

    #ifdef HEXAGON
    // Rectangle normals: Any two will do. By the way, there's nothing
    // stopping you from declaring all four normals for all surrounding
    // walls, but since you know only two will be in front of the
    // direction ray at any given time, it makes sense to only choose
    // two.
    //
    // Declare two normals. Any side by side ones will do.
    vec2 i1 = vec2(.5, .5); // Right forward face index.
    vec2 i2 = vec2(1, 0); // Right face index.
    vec2 i3 = vec2(-.5, .5); // Left forward face index.
    vec2 n1 = vec2(.5, sqrt3/2.); // Right forward.
    vec2 n2 = vec2(1, 0); // Right face normal.
    vec2 n3 = vec2(-.5, sqrt3/2.); // Left
    
    // If the cell wall is behind the ray (or the ray is facing the opposing cell
    // wall, if you prefer), use the normal index from the back cell wall. This 
    // trick is possible because of the rectangle symmetry. As an aside, for 
    // anyone who doesn't know, dotting the direction ray with the face normal 
    // is something you do in software engines for back face culling.
    float d1 = dot(rd.xz, n1), d2 = dot(rd.xz, n2), d3 = dot(rd.xz, n3); 
    // As discussed above.
    if(d1<0.) { i1 *= -1.; n1 *= -1.; }
    if(d2<0.) { i2 *= -1.; n2 *= -1.; }
    if(d3<0.) { i3 *= -1.; n3 *= -1.; }
    #else
    // Rectangle normals: Any two will do. By the way, there's nothing
    // stopping you from declaring all four normals for all surrounding
    // walls, but since you know only two will be in front of the
    // direction ray at any given time, it makes sense to only choose
    // two.
    //
    // Declare two normals. Any side by side ones will do.
    vec2 n1 = vec2(-1, 0), n2 = vec2(0, -1); // Right and top edges.
    
    // If the cell wall is behind the ray (or the ray is facing the opposing cell
    // wall, if you prefer), use the normal index from the back cell wall. This 
    // trick is possible because of the rectangle symmetry. As an aside, for 
    // anyone who doesn't know, dotting the direction ray with the face normal 
    // is something you do in software engines for back face culling.
    float d1 = dot(rd.xz, n1), d2 = dot(rd.xz, n2);
    
    n1 = d1<0.? -n1 : n1;
    n2 = d2<0.? -n2 : n2;
    #endif
    
    
    // Initiate the ray position at the ray origin.
    vec3 pos = ro;
    
    // Obtain the coordinates of the cell that the current ray position 
    // is contained in -- I've arranged for the cell coordinates to 
    // represent the cell center to make things easier.
    vec2 ip = gridID(pos.xz);
    
    float t1 = 1e8, t2 = 1e8, t3 = 1e8, tT = 1e8;
    
    int hit = 0;
    
    
    // Iterate through 24 cells -- Obviously, if the cells were smaller,
    // you'd need more to cover the distance.
    for(int i = 0; i<40; i++){ 

         
        // Height. 
        float ma = h(ip*s);
        
         
        // At this point, we haven't advanced the ray to the back of the cell boundary,
        // so we're at one of the front cell face positions. Therefore, check to see if 
        // we're under the pylon height. If so, we've hit a face, so mark the face as hit, 
        // then break.
        if(pos.y<ma){
            // Hit a side.
            hit = 1;
            break; 
        
        } 
        
        // Ray intersection from the currect cell position to each of the 
        // visible cell walls. Normals face inward.
        // You pass in the current position, the unit direction ray, a known 
        // point on the cell wall (any will do) and the cell wall's normal.
       
        #ifdef HEXAGON
        t1 = rayLine(pos.xz, rd.xz, (ip + i1*.5)*s, -n1);
        t2 = rayLine(pos.xz, rd.xz, (ip + i2*.5)*s, -n2);
        t3 = rayLine(pos.xz, rd.xz, (ip + i3*.5)*s, -n3);
        #else
        t1 = rayLine(pos.xz, rd.xz, (ip + n1*.5)*s, -n1);
        t2 = rayLine(pos.xz, rd.xz, (ip + n2*.5)*s, -n2);
        #endif
        
        // Determine the closest edge then record the closest distance and
        // asign its normal index.
        #ifdef HEXAGON
        vec3 tn = t1<t2 && t1<t3? vec3(t1, i1) : t2<t3? vec3(t2, i2) : vec3(t3, i3);
        #else
        vec3 tn = t1<t2? vec3(t1, n1) : vec3(t2, n2);
        #endif
        
        // Top face distance.
        tT = (ma - pos.y)/rd.y;
        tT = tT<0. ? 1e8 : tT;
        
        
        // We've now advanced to one of the back faces of the cell. Check to see whether
        // we're still under the pylon height, and if so, we've hit the top face --  
        // I always have to think about this, but the logic is that we haven't hit a front
        // cell face and we're still under the height, so we've hit the top. Anyway, mark 
        // the top face as hit, advance the distance in the Y direction to the top face, 
        // then break.
        if(tT<tn.x){
            
            //dist += tT;
            pos += rd*tT; 
            hit = 2;
            break;
             
        }      
         
    
        // If this cell's ID matches the ID of the backgound cell, 
        // flag it as hit in order to color it, or whatever.
        //if(length(cell - ip)<.001){ hit = 1; break; }
        
        // Advance the cell index position by the indices of the 
        // cell wall normal that you hit. 
        ip += tn.yz;
        // Advance the ray position by the distance to the next cell wall.
        pos += rd*tn.x;
    
    }
    
    #ifdef HEXAGON
    float fID = tT<t1 && tT<t2 && tT<t3? 0. : t1<t2 && t1<t3? 1. : t2<t3? 2. : 3.;
    if(fID == 1.){ fID = d1<0.? -fID : fID; }
    else if(fID == 2.){ fID = d2<0.? -fID : fID; }
    else if(fID == 3.){ fID = d3<0.? -fID : fID; }
    #else
    float fID = tT<t1 && tT<t2? 0. : t1<t2? 1. : 2.;
    if(fID == 1.){ fID = d1<0.? -fID : fID; }
    else if(fID == 2.){ fID = d2<0.? -fID : fID; }
    #endif
    
    res.x = length(pos - ro);
    if(hit == 0) res.x = FAR;
    
    return vec4(res.x, fID, ip);
    
}

// Standard normal function.
vec3 nr(float fID, vec3 rd) {

    #ifdef HEXAGON
    vec3 n1 = -vec3(.5, 0, sqrt3/2.); // Right forward.
    vec3 n2 = -vec3(1, 0, 0); // Right face normal.
    vec3 n3 = -vec3(-.5, 0, sqrt3/2.); // Left
    vec3 n = fID == 0.? vec3(0, 1, 0) : abs(fID) == 1.? n1 : abs(fID) == 2.? n2 : n3;
    if(fID<-.001) n *= -1.;
    #else
    vec3 n = fID == 0.? vec3(0, 1, 0) : abs(fID) == 1.? vec3(1, 0, 0) : vec3(0, 0, 1);
    n *= fID<-.001? -1. : 1.;
    #endif
    
    
    return n;
}

// mat3 rotation... I did this in a hurry, but I think it's right. :)
// I have a much better one than this somewhere. 
mat3 rot(vec3 ang){
    
    vec3 c = cos(ang), s = sin(ang);

    return mat3(c.x*c.z - s.x*s.y*s.z, -s.x*c.y, -c.x*s.z - s.x*s.y*c.z,
                c.x*s.y*s.z + s.x*c.z, c.x*c.y, c.x*s.y*c.z - s.x*s.z,
                c.y*s.z, -s.y, c.y*c.z);    
}

void main(){

    vec2 fragCoord = jit_in.uv * viewPort.xy;

    #if BUFF_ACCUM == 2
    // Initial hit point.
    vec3 resPos = vec3(0);
    #endif
    // Overall distance.
    float resT = 0.;

    // Screen pixel coordinates.
    vec2 uv0 = (fragCoord - viewPort.xy*.5)/viewPort.y;
    

    // Initializing the seed value. It needs to be different every frame.
    seed = uv0 + vec2(fract(iTime/113.671)*.123, fract(iTime/57.913)*.14527);
    
    // Ray origin.
    vec3 ro = vec3(-s.x/2. + iTime*.25, 8., iTime*.25); 
    // Setting the camera to the ray origin. The ray origin vector will change
    // from bounce to bounce, so we'll need a record of the initial camera position.
    vec3 cam = ro;
    
    
    // Using the above to produce the unit ray-direction vector.
    float FOV = 1.; // FOV - Field of view.
    
    // Lazy identity camera -- No to and from. I might update it later.
    mat3 mCam = mat3(vec3(1, 0, 0), vec3(0, 1, 0), vec3(0, 0, 1));

 
    mCam *= rot(vec3(0, 0, cos(iTime/8.*.25)/4. + .35)); // Camera yaw.
    mCam *= rot(vec3(-sin(iTime/4.*.25)/8., 0, 0)); // Camera roll.
    mCam *= rot(vec3(0, 1, 0)); // Y axis tilt, or pitch.
    
    
    // Artistic black movie strips. 10% faster "1337" democoder move. :D
    if(abs(uv0.y)>.45) { 
        ivec2 q = ivec2(fragCoord);
        vec4 c = vec4(0, 0, 0, 1); 
        if(q.y == 0 && q.x<3){    
            // Camera matrix in lower left three pixels, for next frame.
            if(q.x == 0) c = vec4(mCam[0], -dot(mCam[0], cam));
            else if(q.x == 1) c = vec4( mCam[1], -dot(mCam[1], cam));
            else c = vec4( mCam[2], -dot(mCam[2], cam));
        } 
        outColor = c;
        return; 
    }
 

    
    // Accumulative color and sample number. 8 is all that my computer can 
    // handle. Some computers would be able to handle more and others less.
    vec3 atot = vec3(0);
    const int sampNum = 16;
    
    for(int j = min(0, iFrame); j<sampNum; j++){
    

        vec2 jit = hash22() - .5;
                        
        vec2 uv = uv0 + jit/viewPort.y;
    
        // Unit direction vector.
        vec3 rd = mCam*normalize(vec3(uv, 1./FOV)); 
 /*       
        // Depth of field. I hacked this in as an afterthought... It seems
        // about right, but I'll have to take a closer look later.
        float fDist = 6.;
        vec2 jitDOF = hash22()*2. - 1.;
        vec3 vDOF = mCam*vec3(jitDOF, 0.)*.06;
        rd = normalize(rd - vDOF/fDist);
        ro = cam + vDOF;
 */
        ro = cam;
        
        // Accumulative, and thoughput.
        vec3 acc = vec3(0);
        
        vec3 through = vec3(1);

        // First hit distance. It's used for fog, amongst other things.
        float t0; 
        
  
        for(int i = min(0, iFrame); i<3; i++){

            // Raycasting
            vec4 res = raycast(ro, rd);

            float t = res.x, d;
            float fID = res.y;
            vec2 id = res.zw;

            t = min(t, FAR); // Clipping to the far distance, which helps avoid artifacts.

            if(i == 0) t0 = t; // Recording the first hit distance.


            // Hit point.
            vec3 p = ro + rd*t;
            
            
            if(i==0){
                #if BUFF_ACCUM == 2
                // Only save the initial hit point and distance. Ignore other bounces.
                resPos += p/float(sampNum); // Accumulative position.
                #endif
                resT += t/float(sampNum); // Accumulative distance.
            }
            
            
    
            // If we've hit an object, light it up.
            if(t<FAR - 1e-6){
            
                
                // Surface normal.
                vec3 n = nr(fID, rd);

                // Scene object color.
                
                 // Local coordinates.
                vec2 lc = p.xz - id*s;
                
                // Texture coordinates, based on a cube mapping routine.
                #ifdef HEXAGON
                vec2 rp = lc*rot2(atan(n.x, n.z));
                vec2 tuv = fID == 0.? p.xz : vec2(rp.x, p.y);
                vec3 tx = texture(iChannel1, tuv/.8660254/3.).xyz; tx *= tx;
                #else
                vec2 tuv = fID == 0.? p.xz : abs(fID) == 1.? p.zy : p.xy;
                vec3 tx = texture(iChannel1, tuv/3.).xyz; tx *= tx;
                #endif

                vec3 oCol = .125 + tx*2.5;
            

                // Edging routine.
                float h0 = h(id*s); // Square prism height.

                float minEdge = min(s.x, s.y)/4.;
                float edge = s.y/4.;
                float edge2 = s.x/4.;

               
         
                // Edge construction.
              
                // Lines eminating from the center to the vertices.
                #ifdef HEXAGON
                const float aNum = 6.;
                vec2 z = rot2(3.14159/aNum)*lc; 
                float a = mod(atan(z.x, z.y), 6.2831)/6.2831;
                a = (floor(a*aNum) + .5)/aNum;
                z *= rot2(a*6.2831);
                // Face edges.
                vec2 ap = abs(lc);
                float fEdge = max(ap.y*.8660254 + ap.x*.5, ap.x) - s.x/2.;
                fEdge = abs(fEdge);
                fEdge = max(fEdge, -(p.y - h0)) - .01;
                float sEdge = max(abs(z.x) - .01, (p.y - (h0 - .01)));
                #else
                // Domain.
                vec2 ap = abs(lc) - s/2.;
                // Face edges.
                float fEdge = max(ap.x, ap.y);
                fEdge = abs(fEdge);
                fEdge = max(fEdge, -(p.y - h0)) - .01;
                // Side edges.
                float sEdge = min(ap.x, ap.y);
                sEdge = max(-sEdge, (p.y - h0)) - .01;
                #endif
           
                // Smoothing facor... Not even sure if it's needed in a multisample
                // example, but it's here anyway.
                //float sf = .004;//*(1. + res.x*res.x*.1);
                
                // Combining the side and face edges, then smoothstepping.
                fEdge = min(fEdge, sEdge);
                
                // Apply the edges.
                oCol = mix(oCol, vec3(0), (1. - step(0., fEdge))*.7);



                // Surface roughness. Larger values are duller in appearance, and lower
                // values are more relective.
                float rough = .9;

                // Substance emissive color. Initialized to zero.
                vec3 emissive = vec3(0);
                
                // If we hit square prism strip, color random windows and set their emission color. 
                if(hash21(id + .103)<.1){
                
                    // Random window color.
                    vec3 eCol = .5 + .45*cos(6.2831*hash21(id +.17)/6. + vec3(0, 1.4, 2));

                    //eCol = mix(eCol, eCol.xzy, clamp((h0 - p.y + .5)/4., 0., 1.));
                    
                    eCol *= sqrt(eCol);
                    
                    // Random emissive color.
                    emissive = oCol*eCol; // Warm hues.
                    if(hash21(id +.027)<.25) emissive = oCol*eCol.zyx; // Random cool hues.
                    // Applying some random green.
                    //emissive = mix(emissive, emissive.xzy, floor(hash21(id +.42)*4.999)/4.*.35);
                    // Pink. Too much.
                    //if(hash21(id +.33)<.2) emissive = mix(emissive, emissive.xzy, .5);
                    

                    // Randomly turn lights on and off for some visual interest.
                    float blink = smoothstep(.2, .3, sin(6.2831*hash21(id + .09) + iTime/1.)*.5 + .5);
                    emissive *= mix(1., 0., blink);
                   
                    // Ramp up the emissive power.
                    emissive *= 16.; 
                    
                    // Make the glowing pylons less rough, and randomize a bit.
                    rough = mix(.5, rough, blink);//hash21(id + .21)*.5 + .25;
                }
                else {
                    // Subtly Color the other pylons.
                    oCol *= (1. + .25*cos(hash21(id + .06)*6.2831/4. + vec3(0, 1, 2)));
    
                }
                
                //rough *= hash21(floor(tuv*8.) + .21)*.7 + .3;

 
                // Tapering emission into the distance.
                //emissive = mix(emissive, vec4(0), smoothstep(.25, .99, t0/FAR));

                // If an emissive sustance has been hit, use it to light the surface.
                acc += emissive*through;
                through *= oCol; // Integrate colors from previous surfaces. 

                
                vec3 ref = reflect(rd, n); // Purely reflected vector.
                vec3 rrd = cosDir(0., n); // Random half hemisphere vector.

                // Mimicking surface inconsistancies with fuzzy reflections.
                // Rougher surfaces have a greater chance of random reflecting at any direction and
                // smoother surfaces are more likely to purely reflect.
                float rChance = step(0., rough - hash21(uv + vec2(i*277, j*113) + fract(iTime*.513 + .137)));
                rd = (mix(ref, rrd, rChance));
                // Other variations. Not physically correct, but they have their purposes.
                //float rChance = rough*hash21(uv + vec2(i*277, j*113) + fract(iTime*.97 + .137));
                //rd = normalize(ref + rrd*rChance);
                //rd = normalize(mix(ref, rrd, rough));
                //rd = normalize(ref + normalize(rnd23() - .5)*rChance);  
                //rd = normalize(ref + rrd*rough);

                // Bump the ray off of the hit surface to avoid self collision.
                ro = p + n*.001;

            }
            else { 
                // If the scene hasn't been hit, add a touch of atmospheric haze, then quit.
                vec3 aCol = vec3(.03, .02, .04)*2.;
                acc += aCol*through; 
                break;
            }

    
        }
       
        // Very simple sky fog, or whatever. Not really the way you apply atmosphere in a 
        // path tracer, but way, way cheaper. :)
        // vec3 sky = mix(vec3(1, .7, .5), vec3(.4, .6, 1), uv0.y*2.5 - .15)*1.5;//vec4(.6, .75, 1, 0)/.6
        //acc = mix(acc, sky/32., smoothstep(.35, .99, t0/FAR));
        
        
        // Add this sample to the running total.
        atot += acc;
        
    }
    
    vec3 col = atot/float(sampNum);
    
    
    // Toning down the high frequency values. A simple Reinhard toner would 
    // get the job done, but I've dropped in a heavily modified and trimmed 
    // down Uncharted 2 tone mapping formula.
    // mapping function.
    col = uTone(col.xyzx).xyz; 
    
     
    
    
    // This is IQ's temporal reprojection code: It's well written and
    // it makes sense. I wrote some 2D reprojection code and was not
    // looking forward to writing the 3D version, and then this 
    // suddenly appeared on Shadertoy. If you're interested in rigid 
    // realtime path traced scenes with slowly moving cameras, this is 
    // much appreciated. :)
    //
    #if BUFF_ACCUM == 2
    //-----------------------------------------------
    // Reproject to previous frame and pull history.
    //-----------------------------------------------
    
    float kFocLen = 1./FOV;
    vec3 pos = resPos;
    ivec2 q = ivec2(fragCoord);
    col = clamp(col, 0., 1.);

    // Fetch previous camera matrix from the bottom left three pixels.
    mat3x4 oldCam = mat3x4(texelFetch(iChannel3, ivec2(0, 0), 0),
                           texelFetch(iChannel3, ivec2(1, 0), 0),
                           texelFetch(iChannel3, ivec2(2, 0), 0));
    // World space point.
    vec4 wpos = vec4(pos, 1.);
    // Convert to camera space (note inverse multiply).
    vec3 cpos = wpos*oldCam;
    // Convert to NDC space (project).
    vec2 npos = (kFocLen*2.)*cpos.xy/cpos.z;//*iRes/viewPort.y;
    // Convert to screen space.
    vec2 spos = .5 + .5*npos*vec2(viewPort.y/viewPort.x, 1);
    // Convert to raster space.
    vec2 rpos = spos*viewPort.xy;

    // Read color+depth from this point's previous screen location.
    vec4 ocolt = textureLod( iChannel3, spos, 0.);
    // If we consider the data contains the history for this point.
    if(iFrame>0 && resT<FAR && (rpos.y>1.5 ||rpos.x>3.5)){
    
        // Blend with history (it's an IIR low pas filter really).
        col = mix( ocolt.xyz, col, 1./8.);
    }
    
    // Color and depth.
    outColor = vec4(col, resT);
    
    // Output.
    if(q.y == 0 && q.x<3){
    
        // Camera matrix in lower left three pixels, for next frame.
        if(q.x == 0) outColor = vec4(mCam[0], -dot(mCam[0], cam));
        else if(q.x == 1) outColor = vec4( mCam[1], -dot(mCam[1], cam));
        else outColor = vec4( mCam[2], -dot(mCam[2], cam));
    } 
    #elif BUFF_ACCUM == 1
    // Mix the previous frames in with no camera reprojection.
    // It's OK, but full temporal blur will be experienced.
    vec4 preCol = texelFetch(iChannel3, ivec2(fragCoord), 0);
    float blend = (iFrame < 2) ? 1. : 1./4.; 
    outColor = mix(preCol, vec4(clamp(col, 0., 1.), resT), blend);
    #else
    // No reprojection or temporal blur, for comparisson.
    outColor = vec4(max(col, 0.), resT);
    #endif
    

    
}
]]>
</program>
</language>
</jittershader>
