<jittershader name="default">
	<description>Default Slab </description>
	<param name="MVP" type="mat4" state="MODELVIEW_PROJECTION_MATRIX" />
	<param name="pos" type="vec3" state="POSITION" />
	<param name="uv" type="vec2" state="TEXCOORD" />

	<param name="viewPort" type="vec2" state="VIEWPORT" />
	<param name="iTime" type="float" default="0.0" />
	<param name="iFrame" type="int" default="0" />
	<param name="iChannel0" type="int" default="0" />
	<param name="iChannel1" type="int" default="1" />

	<language name="glsl" version="1.5">

		<bind param="MVP" program="vp" />
		<bind param="pos" program="vp" />
		<bind param="uv" program="vp" />

		<bind param="viewPort" program="fp" />
		<bind param="iTime" program="fp" />
		<bind param="iFrame" program="fp" />
		<bind param="iChannel0" program="fp" />
		<bind param="iChannel1" program="fp" />

		<program name="vp" type="vertex"  >
		<![CDATA[
			#version 330 core
			
			in vec3 pos;
			in vec2 uv;

			out jit_PerVertex {
				vec2 uv;

			} jit_out;
			uniform mat4 MVP;

			
			void main(void) {
				gl_Position = MVP*vec4(pos, 1.);
				jit_out.uv = uv;
			}
		]]>
		</program>
		
<program name="fp" type="fragment"  >
<![CDATA[
#version 330 core

in jit_PerVertex {
vec2 uv;

} jit_in;
layout (location = 0) out vec4 rgba;

uniform vec2 viewPort;
uniform float iTime;
uniform int iFrame;
uniform sampler2D iChannel0;
uniform sampler2D iChannel1;

#define kScreenDownsample 1

// *******************************************************************************************************
// Global variables

vec2 gResolution;
vec2 gFragCoord;
float gTime;
uvec4 rngSeed;
float gDxyDuv;

void SetGlobals(vec2 fragCoord, vec2 resolution, float time)
{
    gFragCoord = fragCoord;
    gResolution = resolution;
    gTime = time;
    
     // First derivative of screen to world space (assuming square pixels)
    gDxyDuv = 1.0 / gResolution.x;
}

// *******************************************************************************************************
//    Math functions
// *******************************************************************************************************

#define kPi                    3.14159265359
#define kTwoPi                 (2.0 * kPi)
#define kHalfPi                (0.5 * kPi)
#define kRoot2                 1.41421356237
#define kFltMax                3.402823466e+38
#define kIntMax                0x7fffffff
#define kOne                   vec3(1.0)
#define kZero                  vec3(0.0)
#define kPink                  vec3(1.0, 0.0, 0.2)

float cubrt(float a)           { return sign(a) * pow(abs(a), 1.0 / 3.0); }
float toRad(float deg)         { return kTwoPi * deg / 360.0; }
float toDeg(float rad)         { return 360.0 * rad / kTwoPi; }
float sqr(float a)             { return a * a; }
vec3 sqr(vec3 a)               { return a * a; }
int sqr(int a)                 { return a * a; }
float cub(float a)             { return a * a * a; }
int mod2(int a, int b)         { return ((a % b) + b) % b; }
float mod2(float a, float b)   { return mod(mod(a, b) + b, b); }
vec3 mod2(vec3 a, vec3 b)      { return mod(mod(a, b) + b, b); }
float length2(vec2 v)          { return dot(v, v); }
float length2(vec3 v)          { return dot(v, v); }
int sum(ivec2 a)               { return a.x + a.y; }
float luminance(vec3 v)        { return v.x * 0.17691 + v.y * 0.8124 + v.z * 0.01063; }
float mean(vec3 v)             { return v.x / 3.0 + v.y / 3.0 + v.z / 3.0; }
vec4 mul4(vec3 a, mat4 m)      { return vec4(a, 1.0) * m; }
vec3 mul3(vec3 a, mat4 m)      { return (vec4(a, 1.0) * m).xyz; }
float sin01(float a)           { return 0.5 * sin(a) + 0.5; }
float cos01(float a)           { return 0.5 * cos(a) + 0.5; }
float saturate(float a)        { return clamp(a, 0.0, 1.0); }
vec3 saturate(vec3 a)          { return clamp(a, 0.0, 1.0); }
vec4 saturate(vec4 a)          { return clamp(a, 0.0, 1.0); }
float saw01(float a)           { return abs(fract(a) * 2.0 - 1.0); }
float cwiseMax(vec3 v)         { return (v.x > v.y) ? ((v.x > v.z) ? v.x : v.z) : ((v.y > v.z) ? v.y : v.z); }
float cwiseMax(vec2 v)         { return (v.x > v.y) ? v.x : v.y; }
float cwiseMin(vec3 v)         { return (v.x < v.y) ? ((v.x < v.z) ? v.x : v.z) : ((v.y < v.z) ? v.y : v.z); }
float cwiseMin(vec2 v)         { return (v.x < v.y) ? v.x : v.y; }
void sort(inout float a, inout float b) { if(a > b) { float s = a; a = b; b = s; } }
void swap(inout float a, inout float b) { float s = a; a = b; b = s; }

vec3 safeAtan(vec3 a, vec3 b)
{
    vec3 r;
    #define kAtanEpsilon 1e-10
    r.x = (abs(a.x) < kAtanEpsilon && abs(b.x) < kAtanEpsilon) ? 0.0 : atan(a.x, b.x); 
    r.y = (abs(a.y) < kAtanEpsilon && abs(b.y) < kAtanEpsilon) ? 0.0 : atan(a.y, b.y); 
    r.z = (abs(a.z) < kAtanEpsilon && abs(b.z) < kAtanEpsilon) ? 0.0 : atan(a.z, b.z); 
    return r;
}

// *******************************************************************************************************
//    2D SVG
// *******************************************************************************************************

float SDFLine(vec2 p, vec2 v0, vec2 v1, float thickness)
{
    v1 -= v0;
    float t = saturate((dot(p, v1) - dot(v0, v1)) / dot(v1, v1));
    vec2 perp = v0 + t * v1;
    return saturate((thickness - length(p - perp)) / gDxyDuv);
}

float SDFQuad(vec2 p, vec2 v[4], float thickness)
{
    float c = 0.0;
    for(int i = 0; i < 4; i++)
    {
        c = max(c, SDFLine(p, v[i], v[(i+1)%4], thickness)); 
    }
 
    return c;
}

// *******************************************************************************************************
//    2D primitive tests
// *******************************************************************************************************

bool IsPointInQuad(vec2 uv, vec2 v[4])
{
    for(int i = 0; i < 4; i++)
    {
        if(dot(uv - v[i], v[i] - v[(i+1)%4]) > 0.0) { return false; }
    }
    return true;
}

// *******************************************************************************************************
//    Transforms 
// *******************************************************************************************************

mat3 WorldToViewMatrix(float rot, vec2 trans, float sca)
{   
    return mat3(vec3(cos(rot) / sca, sin(rot) / sca, trans.x), 
                vec3(-sin(rot) / sca, cos(rot) / sca, trans.y),
                vec3(1.0));
}

vec2 TransformScreenToWorld(vec2 p)
{   
    return (p - vec2(gResolution.xy) * 0.5) / float(gResolution.y); 
}


vec3 Cartesian2DToBarycentric(vec2 p)
{    
    return vec3(p, 0.0) * mat3(vec3(0.0, 1.0 / 0.8660254037844387, 0.0),
                          vec3(1.0, 0.5773502691896257, 0.0),
                          vec3(-1.0, 0.5773502691896257, 0.0));    
}

vec2 BarycentricToCartesian2D(vec3 b)
{    
    return vec2(b.y * 0.5 - b.z * 0.5, b.x * 0.8660254037844387);    
}

// Maps an input uv position to periodic hexagonal tiling
//     inout vec2 uv: The mapped uv coordinate
//     out vec3 bary: The Barycentric coordinates at the point on the hexagon
//     out ivec2 ij: The coordinate of the tile
vec2 Cartesian2DToHexagonalTiling(in vec2 uv, out vec3 bary, out ivec2 ij)
{    
    #define kHexRatio vec2(1.5, 0.8660254037844387)
    vec2 uvClip = mod(uv + kHexRatio, 2.0 * kHexRatio) - kHexRatio;
    
    ij = ivec2((uv + kHexRatio) / (2.0 * kHexRatio)) * 2;
    if(uv.x + kHexRatio.x <= 0.0) ij.x -= 2;
    if(uv.y + kHexRatio.y <= 0.0) ij.y -= 2;
    
    bary = Cartesian2DToBarycentric(uvClip);
    if(bary.x > 0.0)
    {
        if(bary.z > 1.0) { bary += vec3(-1.0, 1.0, -2.0); ij += ivec2(-1, 1); }
        else if(bary.y > 1.0) { bary += vec3(-1.0, -2.0, 1.0); ij += ivec2(1, 1); }
    }
    else
    {
        if(bary.y < -1.0) { bary += vec3(1.0, 2.0, -1.0); ij += ivec2(-1, -1); }
        else if(bary.z < -1.0) { bary += vec3(1.0, -1.0, 2.0); ij += ivec2(1, -1); }
    }

    return vec2(bary.y * 0.5773502691896257 - bary.z * 0.5773502691896257, bary.x);
}

bool InverseSternograph(inout vec2 uv, float zoom)
{
    float theta = length(uv) * kPi * zoom;
    if(theta >= kPi - 1e-1) { return false; }
    
    float phi = atan(-uv.y, -uv.x) + kPi;
    
    vec3 sph = vec3(cos(phi) * sin(theta), sin(phi) * sin(theta), -cos(theta));
    
    uv = vec2(sph.x / (1.0 - sph.z), sph.y / (1.0 - sph.z));
    return true;
}

float SmoothStep(float a, float b, float x) { return mix(a, b, x * x * (3.0 - 2.0 * x)); }
vec4 SmoothStep(vec4 a, vec4 b, float x)    { return mix(a, b, x * x * (3.0 - 2.0 * x)); }
float SmoothStep(float x)                   { return mix(0.0, 1.0, x * x * (3.0 - 2.0 * x)); }

float PaddedSmoothStep(float x, float a, float b)
{ 
    return SmoothStep(saturate(x * (a + b + 1.0) - a));
}

float PaddedSmoothStep(float x, float a)
{
    return PaddedSmoothStep(x, a, a);
}

float Impulse(float x, float axis, float stdDev)
{
    return exp(-sqr((x - axis) / stdDev));
}

float KickDrop(float t, vec2 p0, vec2 p1, vec2 p2, vec2 p3)
{
    if(t < p1.x)
    {
        return mix(p0.y, p1.y, max(0.0, exp(-sqr((t - p1.x)*2.145966026289347/(p1.x-p0.x))) - 0.01) / 0.99);
    }
    else if(t < p2.x)
    {
        return mix(p1.y, p2.y, (t - p1.x) / (p2.x - p1.x));
    }
    else
    {  
        return mix(p3.y, p2.y, max(0.0, exp(-sqr((t - p2.x)*2.145966026289347/(p3.x-p2.x))) - 0.01) / 0.99);
    }
}

float KickDrop(float t, vec2 p0, vec2 p1, vec2 p2)
{
    return KickDrop(t, p0, p1, p1, p2);
}

// *******************************************************************************************************
//    Random number generation
// *******************************************************************************************************

// Permuted congruential generator from "Hash Functions for GPU Rendering" (Jarzynski and Olano)
// http://jcgt.org/published/0009/03/02/paper.pdf
uvec4 PCGAdvance()
{
    rngSeed = rngSeed * 1664525u + 1013904223u;
    
    rngSeed.x += rngSeed.y*rngSeed.w; 
    rngSeed.y += rngSeed.z*rngSeed.x; 
    rngSeed.z += rngSeed.x*rngSeed.y; 
    rngSeed.w += rngSeed.y*rngSeed.z;
    
    rngSeed ^= rngSeed >> 16u;
    
    rngSeed.x += rngSeed.y*rngSeed.w; 
    rngSeed.y += rngSeed.z*rngSeed.x; 
    rngSeed.z += rngSeed.x*rngSeed.y; 
    rngSeed.w += rngSeed.y*rngSeed.z;
    
    return rngSeed;
}

// Generates a tuple of canonical random number and uses them to sample an input texture
vec4 Rand(sampler2D sampler)
{
    return texelFetch(sampler, (ivec2(gFragCoord) + ivec2(PCGAdvance() >> 16)) % 1024, 0);
}

// Generates a tuple of canonical random numbers in the range [0, 1]
vec4 Rand()
{
    return vec4(PCGAdvance()) / float(0xffffffffu);
}

// Seed the PCG hash function with the current frame multipled by a prime
void PCGInitialise(uint seed)
{    
    rngSeed = uvec4(20219u, 7243u, 12547u, 28573u) * seed;
}

// Reverse the bits of 32-bit inteter
uint RadicalInverse(uint i)
{
    i = ((i & 0xffffu) << 16u) | (i >> 16u);
    i = ((i & 0x00ff00ffu) << 8u) | ((i & 0xff00ff00u) >> 8u);
    i = ((i & 0x0f0f0f0fu) << 4u) | ((i & 0xf0f0f0f0u) >> 4u);
    i = ((i & 0x33333333u) << 2u) | ((i & 0xccccccccu) >> 2u);    
    i = ((i & 0x55555555u) << 1u) | ((i & 0xaaaaaaaau) >> 1u);        
    return i;
}

// Samples the radix-2 Halton sequence from seed value, i
float HaltonBase2(uint i)
{    
    return float(RadicalInverse(i)) / float(0xffffffffu);
}

const mat4 kOrderedDither = mat4(vec4(0.0, 8.0, 2.0, 10.), vec4(12., 4., 14., 6.), vec4(3., 11., 1., 9.), vec4(15., 7., 13., 5.));
float OrderedDither()
{    
    return (kOrderedDither[int(gFragCoord.x) & 3][int(gFragCoord.y) & 3] + 1.0) / 17.0;
}

float OrderedDither(ivec2 p)
{    
    return (kOrderedDither[p.x & 3][p.y & 3] + 1.0) / 17.0;
}

// *******************************************************************************************************
//    Hash functions
// *******************************************************************************************************

// Constants for the Fowler-Noll-Vo hash function
// https://en.wikipedia.org/wiki/Fowler-Noll-Vo_hash_function
#define kFNVPrime              0x01000193u
#define kFNVOffset             0x811c9dc5u
#define kDimsPerBounce         4

// Mix and combine two hashes
uint HashCombine(uint a, uint b)
{
    return (((a << (31u - (b & 31u))) | (a >> (b & 31u)))) ^
            ((b << (a & 31u)) | (b >> (31u - (a & 31u))));
}

// Compute a 32-bit Fowler-Noll-Vo hash for the given input
uint HashOf(uint i)
{
    uint h = (kFNVOffset ^ (i & 0xffu)) * kFNVPrime;
    h = (h ^ ((i >> 8u) & 0xffu)) * kFNVPrime;
    h = (h ^ ((i >> 16u) & 0xffu)) * kFNVPrime;
    h = (h ^ ((i >> 24u) & 0xffu)) * kFNVPrime;
    return h;
}

uint HashOf(uint a, uint b) { return HashCombine(HashOf(a), HashOf(b)); }
uint HashOf(uint a, uint b, uint c) { return HashCombine(HashCombine(HashOf(a), HashOf(b)), HashOf(c)); }
uint HashOf(uint a, uint b, uint c, uint d) { return HashCombine(HashCombine(HashOf(a), HashOf(b)), HashCombine(HashOf(c), HashOf(d))); }
uint HashOf(ivec2 v) { return HashCombine(HashOf(uint(v.x)), HashOf(uint(v.y))); }

// Samples the radix-2 Halton sequence from seed value, i
float HashToFloat(uint i)
{    
    return float(i) / float(0xffffffffu);
}

// *******************************************************************************************************
//    Colour functions
// *******************************************************************************************************

vec3 Hue(float phi)
{
    float phiColour = 6.0 * phi;
    int i = int(phiColour);
    vec3 c0 = vec3(((i + 4) / 3) & 1, ((i + 2) / 3) & 1, ((i + 0) / 3) & 1);
    vec3 c1 = vec3(((i + 5) / 3) & 1, ((i + 3) / 3) & 1, ((i + 1) / 3) & 1);             
    return mix(c0, c1, phiColour - float(i));
}

vec3 HSVToRGB(vec3 hsv)
{
    return mix(vec3(0.0), mix(vec3(1.0), Hue(hsv.x), hsv.y), hsv.z);
}

vec3 RGBToHSV( vec3 rgb)
{
    // Value
    vec3 hsv;
    hsv.z = cwiseMax(rgb);

    // Saturation
    float chroma = hsv.z - cwiseMin(rgb);
    hsv.y = (hsv.z < 1e-10) ? 0.0 : (chroma / hsv.z);

    // Hue
    if (chroma < 1e-10)        { hsv.x = 0.0; }
    else if (hsv.z == rgb.x)    { hsv.x = (1.0 / 6.0) * (rgb.y - rgb.z) / chroma; }
    else if (hsv.z == rgb.y)    { hsv.x = (1.0 / 6.0) * (2.0 + (rgb.z - rgb.x) / chroma); }
    else                        { hsv.x = (1.0 / 6.0) * (4.0 + (rgb.x - rgb.y) / chroma); }
    hsv.x = fract(hsv.x + 1.0);

    return hsv;
}

vec3 Overlay(vec3 a, vec3 b)
{
    //return (luminance(a) < 0.5) ? (2.0 * a * b) : (1.0 - 2.0 * (1.0 - a) * (1.0 - b));
    return vec3((a.x < 0.5) ? (2.0 * a.x * b.x) : (1.0 - 2.0 * (1.0 - a.x) * (1.0 - b.x)),
                (a.y < 0.5) ? (2.0 * a.y * b.y) : (1.0 - 2.0 * (1.0 - a.y) * (1.0 - b.y)),
                (a.z < 0.5) ? (2.0 * a.z * b.z) : (1.0 - 2.0 * (1.0 - a.z) * (1.0 - b.z)));
}

vec3 SoftLight(vec3 a, vec3 b)
{
    return (kOne - 2.0 * b) * sqr(a) + 2.0 * b * a;
}

// A Gaussian function that we use to sample the XYZ standard observer 
float CIEXYZGauss(float lambda, float alpha, float mu, float sigma1, float sigma2)
{
   return alpha * exp(sqr(lambda - mu) / (-2.0 * sqr(lambda < mu ? sigma1 : sigma2)));
}

vec3 SampleSpectrum(float delta)
{
	// Here we use a set of fitted Gaussian curves to approximate the CIE XYZ standard observer.
	// See https://en.wikipedia.org/wiki/CIE_1931_color_space for detals on the formula
	// This allows us to map the sampled wavelength to usable RGB values. This code needs cleaning 
	// up because we do an unnecessary normalisation steps as we map from lambda to XYZ to RGB.

    float lambda = mix(3800.0, 7000.0, delta);    

	#define kRNorm (7000.0 - 3800.0) / 1143.07
	#define kGNorm (7000.0 - 3800.0) / 1068.7
	#define kBNorm (7000.0 - 3800.0) / 1068.25

	// Sample the Gaussian approximations
	vec3 xyz;
	xyz.x = (CIEXYZGauss(lambda, 1.056, 5998.0, 379.0, 310.0) +
             CIEXYZGauss(lambda, 0.362, 4420.0, 160.0, 267.0) +
             CIEXYZGauss(lambda, 0.065, 5011.0, 204.0, 262.0)) * kRNorm;
	xyz.y = (CIEXYZGauss(lambda, 0.821, 5688.0, 469.0, 405.0) +
             CIEXYZGauss(lambda, 0.286, 5309.0, 163.0, 311.0)) * kGNorm;
	xyz.z = (CIEXYZGauss(lambda, 1.217, 4370.0, 118.0, 360.0) +
             CIEXYZGauss(lambda, 0.681, 4590.0, 260.0, 138.0)) * kBNorm;

	// XYZ to RGB linear transform
	vec3 rgb;
	rgb.r = (2.04159 * xyz.x - 0.5650 * xyz.y - 0.34473 * xyz.z) / (2.0 * 0.565);
	rgb.g = (-0.96924 * xyz.x + 1.87596 * xyz.y + 0.04155 * xyz.z) / (2.0 * 0.472);
	rgb.b = (0.01344 * xyz.x - 0.11863 * xyz.y + 1.01517 * xyz.z) / (2.0 * 0.452);

	return rgb;
}

// *******************************************************************************************************
//    Filters
// *******************************************************************************************************
#define kApplyBloom               true

#define kBloomGain                1.         // The strength of the bloom effect 
#define kBloomTint                vec3(1.0)       // The tint applied to the bloom effect
#define kBloomWidth               (0.02 / float(kScreenDownsample))             // The width of the bloom effect as a proportion of the buffer width
#define kBloomHeight              (0.02 / float(kScreenDownsample))             // The height of the bloom effect as a proportion of the buffer height
#define kBloomShape               vec3(1.5, 1.0, 0.7)            // The fall-off of the bloom shape. Higher value = steeper fall-off
#define kBloomDownsample          2               // How much the bloom buffer is downsampled. Higher value = lower quality, but faster
#define kDebugBloom               false           // Show only the bloom in the final comp
#define kBloomBurnIn              vec3(0.2) 

// Seperable bloom function. This filter requires two passes in the horizontal and vertical directions which are combined as a post-process
// effect after each frame. The accuracy/cost of the effect can be tuned by dialing the kBloomDownsample parameter. 
// vec3 Bloom(vec2 fragCoord, vec3 viewPort, ivec2 delta, sampler2D renderSampler)
// {        
//     vec2 scaledResolution = vec2(viewPort.x, viewPort.y) / float((delta.x == 1) ? kBloomDownsample : 1);
   
//     if(fragCoord.x > scaledResolution.x || fragCoord.y > scaledResolution.y) { return kZero; }
    
//     float bloomSize = (delta.x == 1) ? kBloomWidth : kBloomHeight;
    
//     int kKernelWidth = int(bloomSize * max(viewPort.x, viewPort.y) + 0.5) / ((delta.x == 1) ? kBloomDownsample : 1);
//     vec3 sumWeights = vec3(0.0);
//     vec3 sumRgb = vec3(0.0);
//     for(int i = -kKernelWidth; i <= kKernelWidth; i++)
//     {      
//         vec2 xy = vec2(fragCoord.x + float(i * delta.x), fragCoord.y + float(i * delta.y));
        
//         if(delta.x == 1) { xy *= float(kBloomDownsample); }
//         else { xy /= float(kBloomDownsample); }
        
//         if(xy.x < 0.0 || xy.x > viewPort.x || xy.y < 0.0 || xy.y > viewPort.y) { continue; }
            
//         vec4 texel = texture(renderSampler, xy / viewPort.xy);
//         vec3 rgb = max(texel.xyz / max(1.0, texel.w), vec3(0.0));            
//         float d = float(abs(i)) / float(kKernelWidth);
           
//         vec3 weight = kOne;
//         if(i != 0)
//         {
//             // Currently using a single weight although this effect can be done per-channel
//             weight = pow(max(kZero, kOne * (exp(-sqr(d * 4.0)) - 0.0183156) / 0.981684), kBloomShape);
//         }
            
//         sumRgb += ((delta.y == 1) ? rgb : max(kZero, rgb - kBloomBurnIn)) * weight;         
//         sumWeights += weight;
//     }
    
//     sumRgb = sumRgb / sumWeights;
    
//     return (delta.x == 1) ? sumRgb : (sumRgb * kBloomTint);
// }

vec3 Bloom(vec2 fragCoord, vec2 viewPort, ivec2 delta, sampler2D renderSampler)
{        
    vec2 scaledResolution = vec2(viewPort.x, viewPort.y) / float((delta.x == 1) ? kBloomDownsample : 1);
   
    if(fragCoord.x > scaledResolution.x || fragCoord.y > scaledResolution.y) { return kZero; }
    
    float bloomSize = (delta.x == 1) ? kBloomWidth : kBloomHeight;
    
    int kKernelWidth = int(bloomSize * max(viewPort.x, viewPort.y) + 0.5) / ((delta.x == 1) ? kBloomDownsample : 1);
    vec3 sumWeights = vec3(0.0);
    vec3 sumRgb = vec3(0.0);
    for(int i = -kKernelWidth; i <= kKernelWidth; i++)
    {      
        vec2 xy = vec2(fragCoord.x + float(i * delta.x), fragCoord.y + float(i * delta.y));
        
        if(delta.x == 1) { xy *= float(kBloomDownsample); }
        else { xy /= float(kBloomDownsample); }
        
        if(xy.x < 0.0 || xy.x > viewPort.x || xy.y < 0.0 || xy.y > viewPort.y) { continue; }
            
        vec4 texel = texture(renderSampler, xy / viewPort);
        vec3 rgb = max(texel.xyz / max(1.0, texel.w), vec3(0.0));            
        float d = float(abs(i)) / float(kKernelWidth);
           
        vec3 weight = kOne;
        if(i != 0)
        {
            // Currently using a single weight although this effect can be done per-channel
            weight = pow(max(kZero, kOne * (exp(-sqr(d * 4.0)) - 0.0183156) / 0.981684), kBloomShape);
        }
            
        sumRgb += ((delta.y == 1) ? rgb : max(kZero, rgb - kBloomBurnIn)) * weight;         
        sumWeights += weight;
    }
    
    sumRgb = sumRgb / sumWeights;
    
    return (delta.x == 1) ? sumRgb : (sumRgb * kBloomTint);
}


//BufferA//

#define kCaptureTimeDelay 0.0
#define kCaptureTimeSpeed 1.0

vec3 Render(vec2 uvScreen, int idx, int maxSamples, bool isDisplaced, float jpegDamage, out float blend)
{       
    #define kMBlurGain      (isDisplaced ? 100. : 10.0)
    #define kZoomOrder      2
    #define kEndPause       0.0
    #define kSpeed          0.15
     
    // x: Lambda
    // y: Motion blur
    // z, w: Warping and distortion
    
    // Sample the time domain for motion blur
    vec4 xi = Rand(iChannel0);
    uint hash = HashOf(uint(98796523), uint(gFragCoord.x), uint(gFragCoord.y));        
    xi.y = (float(idx) + HaltonBase2(uint(idx) + hash)) / float(maxSamples);
    //xi.x = OrderedDither();
    xi.x = xi.y;
    float time = 1. * max(0.0, iTime - kCaptureTimeDelay);
    time = (time * kCaptureTimeSpeed + xi.y * kMBlurGain / 60.0) * kSpeed; 
    //time = time - 0.2 * sqrt(uvScreen.y / viewPort.y);
    
    float phase = fract(time);
    int interval = int(time) & 1;    
    interval <<= 1;
    float morph;
    float warpedTime;
    float spectrumBlend;
    #define kIntervalPartition 0.85
    if(phase < kIntervalPartition)
    {
        float y = (interval == 0) ? uvScreen.y : (viewPort.y - uvScreen.y);
        warpedTime = (phase / kIntervalPartition) - 0.2 * sqrt(y / viewPort.y) - 0.1;
        phase = fract(warpedTime);
        morph = 1.0 - PaddedSmoothStep(sin01(kTwoPi * phase), 0., 0.4);
        blend = float(interval / 2) * 0.5;
        if(interval == 2) { warpedTime *= 0.5; }
    }
    else
    {
        time -=  0.8 * kSpeed * xi.y * kMBlurGain / 60.0;
        warpedTime = time;
        phase = (fract(time) - kIntervalPartition) / (1.0 - kIntervalPartition);
        morph = 1.0;
        blend = (KickDrop(phase, vec2(0.0, 0.0), vec2(0.2, -0.1), vec2(0.3, -0.1), vec2(0.7, 1.0)) + float(interval / 2)) * 0.5;        
        interval++;
    }
    
    float beta = abs(2.0 * max(0.0, blend) - 1.0);
    
    #define kMaxIterations  2
    //int kMaxIterations = 2 + 2 * int(round(jpegDamage));
    #define kTurns 7
    #define kNumRipples 5
    //#define kRippleDelay 1.
    #define kRippleDelay (float(kNumRipples) / float(kTurns))
    #define kThickness mix(0.5, 0.4, morph)
    #define kExponent mix(0.05, 0.55, morph)
    
    float expMorph = pow(morph, 0.3);
    //#define kZoom mix(0.3, 0.3, expMorph)
    #define kZoom 0.35
    #define kScale mix(2.6, 1.1, expMorph)
    //float kScale = (exp(5. * (1. - expMorph)) - 1.) + 1.05;
    
    //#define kZoom 0.35
    //#define kScale mix(1.7, 1.3, pow(phase, 0.3))    

    // Apply the transformation matrix and clip to screen space
    mat3 M = WorldToViewMatrix(blend * kTwoPi, vec2(0.0), kZoom);
    vec2 uvView = TransformScreenToWorld(uvScreen);
    int invert = 0;
     
   
    // Defocus blur
    //vec4 blueNoise = texture(iChannel0, vec2(fract(iTime * 0.002), 0.5));
    //blueNoise = pow(saturate((blueNoise - 0.5) / (1.0 - 0.5)), vec4(2.0));
    //uvView += vec2(cos(kTwoPi * xi.z), sin(kTwoPi * xi.z)) * xi.w * 0.05 * blueNoise.x;
    
    // Chromatic aberration
    //uvView /= 1.0 + mix(0.1, 0.5, length(uvView) * xiLambda * blueNoise.y); // Dynamic
    uvView /= 1.0 + 0.05 * length(uvView) * xi.z; // Static
    
    //uvView *= 1.0 + length(uvView) * xi * 0.05;

    uvView = (vec3(uvView, 1.0) * M).xy; 
    
     vec3 bary;
    ivec2 ij;
    Cartesian2DToHexagonalTiling(uvView / 1.4, bary, ij);    
    //float len = cwiseMax(abs(bary * mix(1.2, 1., cos01(1. * kTwoPi * blend))));
    float len = cwiseMax(abs(bary));
    //if(ij == ivec2(0) && len > 0.995 && len <= 1.) invert = 1;
    
    vec2 uvViewWarp = uvView;
    uvViewWarp.y *= mix(1.0, 0.1, sqr(1.0 - morph) * xi.y * saturate(sqr(0.5 * (1.0 + uvView.y))));   
    //uvViewWarp.x += mix(-1.0, 1.0, xi.w) * 0.002;
    
    float theta = toRad(30.0) * beta;
    mat2 r = mat2(vec2(cos(theta), -sin(theta)), vec2(sin(theta), cos(theta)));
    uvViewWarp = r * uvViewWarp;    

    vec3 sigma = vec3(0.0);
    for(int iterIdx = 0; iterIdx < kMaxIterations; ++iterIdx)
    {   
        vec3 bary;
        ivec2 ij;
        Cartesian2DToHexagonalTiling(uvViewWarp, bary, ij);        
                        
        if(!isDisplaced && ij != ivec2(0)) { break; }   
        
        //if(iterIdx == 0 && cwiseMax(abs(bary)) > 0.99) { invert = invert ^ 1; }
        
        int subdiv = 1 + int(exp(-sqr(10. * mix(-1., 1., phase))) * 100.);
        
        float theta = kTwoPi * (floor(cos01(kTwoPi * phase) * 12.) / 6.);
        Cartesian2DToHexagonalTiling(uvViewWarp * (0.1 + float(subdiv)) - kHexRatio.y * vec2(sin(theta), cos(theta)) * floor(0.5 + sin01(kTwoPi * phase) * 2.) / 2., bary, ij);        
        uint hexHash = HashOf(uint(phase * 6.), uint(subdiv), uint(ij.x), uint(ij.y));
        if(hexHash % 2u == 0u)
        {
            float alpha = PaddedSmoothStep(sin01(phase * 20.0), 0.2, 0.75);
            float dist = mix(cwiseMax(abs(bary)), length(uvView) * 2.5, 1.0 - alpha);
            float hashSum = bary[hexHash % 3u] + bary[(hexHash + 1u) % 3u];

            if( dist > 1.0 - 0.02 * float(subdiv)) { invert = invert ^ 1; }
            else if( fract(20. / float(subdiv) * hashSum) < 0.5)  { invert = invert ^ 1; }
            if(iterIdx == 0) break;
        }
        
        float sigma = 0.0, sigmaWeight = 0.0;
        for(int j = 0; j < kTurns; ++j)
        {   
            float delta = float(j) / float(kTurns);
            float theta = kTwoPi * delta;
            for(int i = 0; i < kNumRipples; ++i)
            {
                float l = length(uvViewWarp - vec2(cos(theta), sin(theta))) * 0.5;
                float weight = log2(1.0 / (l + 1e-10));
                sigma += fract(l - pow(fract((float(j) + float(i) / kRippleDelay) / float(kTurns) + warpedTime), kExponent)) * weight;
                sigmaWeight += weight;
            }            
        }
        invert = invert ^ int((sigma / sigmaWeight) > kThickness);
        
        //return vec3(sigma / sigmaWeight); 
       
        theta = kTwoPi * (floor(cos01(kTwoPi * -phase) * 5. * 6.) / 6.);
        uvViewWarp = r * (uvViewWarp + vec2(cos(theta), sin(theta)) * 0.5);
        uvViewWarp *= kScale; 
    }
    
    sigma = vec3(float(invert != 0));
    
    return mix(1.0 - sigma, sigma * mix(kOne, SampleSpectrum(xi.x), sqr(beta)), beta);
}

bool Interfere(inout vec2 xy, inout vec3 tint, in vec2 res)
{
    #define kStatic true
    #define kStaticFrequency 0.1
    #define kStaticLowMagnitude 0.01
    #define kStaticHighMagnitude 0.02
    
    #define kVDisplace true
    #define kVDisplaceFrequency 0.07
    
    #define kHDisplace true
    #define kHDisplaceFrequency 0.25
    #define kHDisplaceVMagnitude 0.1
    #define kHDisplaceHMagnitude 0.5
    
    float frameHash = HashToFloat(HashOf(uint(iFrame / int(10.0 / kCaptureTimeSpeed))));
    bool isDisplaced = false;
    
    if(kStatic)
    {
        // Every now and then, add a ton of static
        float interP = 0.01, displacement = res.x * kStaticLowMagnitude;
        if(frameHash < kStaticFrequency)
        {
            interP = 0.5;
            displacement = kStaticHighMagnitude * res.x;
            tint = vec3(0.5);
        }

        // CRT interference at PAL refresh rate 
        PCGInitialise(HashOf(uint(xy.y / 2.), uint(iFrame / int(60.0 / (24.0 * kCaptureTimeSpeed)))));
        vec4 xi = Rand();
        if(xi.x < interP) 
        {  
            float mag = mix(-1.0, 1.0, xi.y);        
            xy.x -= displacement * sign(mag) * sqr(abs(mag)); 
            //isDisplaced = true;
        }
    }
    
    // Vertical displacment
    if(kVDisplace && frameHash > 1.0 - kVDisplaceFrequency)
    {
        float dispX = HashToFloat(HashOf(8783u, uint(iFrame / int(10.0 / kCaptureTimeSpeed))));
        float dispY = HashToFloat(HashOf(364719u, uint(iFrame / int(12.0 / kCaptureTimeSpeed))));
        
        if(xy.y < dispX * res.y) 
        { 
            xy.y -= mix(-1.0, 1.0, dispY) * res.y * 0.2; 
            isDisplaced = true;
            tint = vec3(3.);
        }
    }
    // Horizontal displacment
    else if(kHDisplace && frameHash > 1.0 - kHDisplaceFrequency - kVDisplaceFrequency)
    {
        float dispX = HashToFloat(HashOf(147251u, uint(iFrame / int(9.0 / kCaptureTimeSpeed))));
        float dispY = HashToFloat(HashOf(287512u, uint(iFrame / int(11.0 / kCaptureTimeSpeed))));
        float dispZ = HashToFloat(HashOf(8756123u, uint(iFrame / int(7.0 / kCaptureTimeSpeed))));
        
        if(xy.y > dispX * res.y && xy.y < (dispX + mix(0.0, kHDisplaceVMagnitude, dispZ)) * res.y) 
        { 
            xy.x -= mix(-1.0, 1.0, dispY) * res.x * kHDisplaceHMagnitude; 
            isDisplaced = true;
            tint = vec3(3.);
        }
    }
    
    return isDisplaced;
}

// Vignetting is an effect caused by composite lenses whereby the image appears darker around the edges.
// Despite being an artefact of lens design, it is often applied deliberately as an artistic effect to 
// frame the image and draw the eye inward toward the center. 
float Vignette(in vec2 fragCoord)
{
    #define kVignetteStrength         0.5             // The strength of the vignette effect
    #define kVignetteScale            0.6            // The scale of the vignette effect
    #define kVignetteExponent         3.0             // The rate of attenuation of the vignette effect
    
    vec2 uv = fragCoord / viewPort.xy;
    uv.x = (uv.x - 0.5) * (viewPort.x / viewPort.y) + 0.5;     
    
    float x = 2.0 * (uv.x - 0.5);
    float y = 2.0 * (uv.y - 0.5);
    
    float dist = sqrt(x*x + y*y) / kRoot2;
    
    return mix(1.0, max(0.0, 1.0 - pow(dist * kVignetteScale, kVignetteExponent)), kVignetteStrength);
}

void main()
{
    vec2 xy = jit_in.uv * viewPort.xy;
    SetGlobals(xy, viewPort.xy, iTime); 
    PCGInitialise(HashOf(uint(iFrame)));
    
    vec3 rgb = kZero;
    if(kApplyBloom)
    {
        vec3 bloom = Bloom(xy / float(kScreenDownsample), viewPort, ivec2(0, 1), iChannel0) * kBloomGain; 
        if(kDebugBloom)
        {
             rgba = vec4(bloom, 1.0);
             return;
        }
        
        rgb = pow(bloom, vec3(1.));      
    }  

    
    // Composite
    rgb += texelFetch(iChannel1, ivec2(xy) / kScreenDownsample, 0).xyz * 0.6;     
    rgb = saturate(rgb);
    rgb = pow(rgb, vec3(0.8));
    rgb = mix(kOne * 0.1, kOne * 0.9, rgb);
    rgb *= Vignette(xy);
    
    rgb = saturate(rgb);
    
    rgba.xyz = rgb;    
    rgba.w = 1.0;
}
]]>
</program>
</language>
</jittershader>