<jittershader name="default">
	<description>Default Slab </description>

	<param name="MVP" type="mat4" state="MODELVIEW_PROJECTION_MATRIX" />
	<param name="position" type="vec3" state="POSITION" />
	<param name="uv" type="vec2" state="TEXCOORD" />

	<param name="viewPort" type="vec2" state="VIEWPORT" />
	<param name="iChannel0" type="int" default="0" />

	<language name="glsl" version="1.5">

		<bind param="MVP" program="vp" />
		<bind param="position" program="vp" />
		<bind param="uv" program="vp" />

		<bind param="viewPort" program="fp" />
		<bind param="iChannel0" program="fp" />

		<program name="vp" type="vertex"  >
		<![CDATA[
			#version 330 core
			
			in vec3 position;
			in vec2 uv;

			out jit_PerVertex {
				vec2 uv;

			} jit_out;
			uniform mat4 MVP;

			
			void main(void) {
				gl_Position = MVP*vec4(position, 1.);
				jit_out.uv = uv;

			}
		]]>
		</program>
		
<program name="fp" type="fragment"  >
<![CDATA[
#version 330 core

in jit_PerVertex {
	vec2 uv;

} jit_in;
layout (location = 0) out vec4 outColor;

uniform vec2 viewPort;
uniform sampler2D iChannel0;

// A real time volumetric with shadows, ambient occlusion, and rayleigh scattering
// I learned to make volume with the video of Sebastian Lague on clouds
// https://www.youtube.com/watch?v=4QOcCGI6xOU
// And I added other features like rayleigh scattering or ambient occlusion
// move the mouse to rotate the camera

// ACES tonemapper
vec3 ACES(vec3 x) {
    float a = 2.51;
    float b =  .03;
    float c = 2.43;
    float d =  .59;
    float e =  .14;
    return (x*(a*x+b))/(x*(c*x+d)+e);
}

// bloom function
vec4 bloom(sampler2D sam, vec2 p) {    
    vec4 col = vec4(0); // accumulated color
    const int N = 8; // quality
    
    for (int i=-N; i<=N; i++)
    for (int j=-N; j<=N; j++)  {
        vec2 off = vec2(i,j) / float(N); // blur offset
        if (dot(off, off)<1.) { // inside disk
            // blurred texture
            col.rgb += textureLod(iChannel0, p+.07*off, 4.).rgb;
            col.a += 1.;
        }
    }
    // output
    return col/col.a;
}

// depth of field function by iq
vec4 dof(sampler2D sam, vec2 p) {
    vec4 col = vec4(0); // accumulated color
    const float focus = 1.3; // focus plane
    const int N = 4; // quality
    
    for (int i=-N; i<=N; i++)
    for (int j=-N; j<=N; j++) {
        vec2 off = vec2(i,j); // blur offset
        // blurred texture
        vec4 tmp = texture(iChannel0, p+off/vec2(800,450)); 
        
        float depth = tmp.w; // depth
        vec3 color = tmp.xyz; // color
        
        float coc = 12.*abs(depth-focus) / depth;
        if(dot(off,off) < coc*coc) { // inside disk (for bokeh)
            float w = 1./(coc*coc); 
            col += vec4(color*w,w);
        }
    }
    // output
    return col/col.a;
}

void main()
{
    vec2 fragCoord = jit_in.uv * viewPort.xy;
    // normalized pixel coordinates
    vec2 p = fragCoord/viewPort.xy;
    // base color + dof
    vec3 col = dof(iChannel0, p).rgb;

    // post processing
    
    col = pow(col, vec3(.4545)); // gamma correction
    // bloom
    vec3 bloom = bloom(iChannel0, p).rgb;
    col += bloom;
    
    col = ACES(col); // tonemapping
    col = 1.2*pow(col,vec3(.9,1,1)); // add a bit of red
    //col = col.xzy;
    col *= .5+.5*pow(16. * p.x*p.y*(1.-p.x)*(1.-p.y), .1); // vignette
            
    outColor = vec4(col,1.0);
}
]]>
</program>
</language>
</jittershader>
